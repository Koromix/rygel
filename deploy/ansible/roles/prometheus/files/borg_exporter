#!/bin/env python3

# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program. If not, see https://www.gnu.org/licenses/.

import argparse
import datetime
import json
import re
import subprocess
from datetime import datetime
from http.server import HTTPServer, BaseHTTPRequestHandler

config = None

def gather_metrics():
    with open(config.info_file, 'r', encoding = 'utf-8') as f:
        stats = json.load(f)
    with open(config.list_file, 'r', encoding = 'utf-8') as f:
        backups = json.load(f)

    metrics = []

    for repo in stats:
        metrics.append({
            'name': 'stats_total_chunks',
            'properties': { 'id': repo['repository']['id'], 'location': repo['repository']['location'] },
            'value': repo['cache']['stats']['total_chunks']
        })
        metrics.append({
            'name': 'stats_total_unique_chunks',
            'properties': { 'id': repo['repository']['id'], 'location': repo['repository']['location'] },
            'value': repo['cache']['stats']['total_unique_chunks']
        })
        metrics.append({
            'name': 'stats_total_size',
            'properties': { 'id': repo['repository']['id'], 'location': repo['repository']['location'] },
            'value': repo['cache']['stats']['total_size']
        })
        metrics.append({
            'name': 'stats_total_csize',
            'properties': { 'id': repo['repository']['id'], 'location': repo['repository']['location'] },
            'value': repo['cache']['stats']['total_csize']
        })
        metrics.append({
            'name': 'stats_unique_size',
            'properties': { 'id': repo['repository']['id'], 'location': repo['repository']['location'] },
            'value': repo['cache']['stats']['unique_size']
        })
        metrics.append({
            'name': 'stats_unique_csize',
            'properties': { 'id': repo['repository']['id'], 'location': repo['repository']['location'] },
            'value': repo['cache']['stats']['unique_csize']
        })

    for bak in backups:
        max_time = 0
        for archive in bak['archives']:
            time = int(datetime.fromisoformat(archive['time']).timestamp())
            max_time = max(max_time, time)

        metrics.append({
            'name': 'backups_count',
            'properties': { 'id': bak['repository']['id'], 'location': bak['repository']['location'] },
            'value': len(bak['archives'])
        })
        metrics.append({
            'name': 'backups_last_time',
            'properties': { 'id': bak['repository']['id'], 'location': bak['repository']['location'] },
            'value': max_time
        })

    return metrics

class ExporterHandler(BaseHTTPRequestHandler):
    def do_GET(self):
        if self.path == '/':
            self.send_response(200)
            self.send_header('Content-type','text/html')
            self.end_headers()

            self.wfile.write(f'Metrics are available at <a href="{config.metrics_path}">{config.metrics_path}</a>'.encode())
        elif self.path == config.metrics_path:
            try:
                metrics = gather_metrics()
            except FileNotFoundError:
                self.send_response(200)
                self.send_header('Content-type','text/plain')
                self.end_headers()
            except:
                self.send_response(500)
                self.end_headers()

            self.export_metrics(metrics)
        else:
            self.send_response(404)
            self.send_header('Content-type','text/plain')
            self.end_headers()

            self.wfile.write('404: URL not found'.encode())

    def export_metrics(self, metrics):
        self.send_response(200)
        self.send_header('Content-type','text/plain')
        self.end_headers()

        for metric in metrics:
            self.wfile.write(f'borg_{metric["name"]}'.encode())
            if metric['properties']:
                for i, (key, value) in enumerate(metric['properties'].items()):
                    self.wfile.write(f'{", " if i > 0 else " {"}{key}="{value}"'.encode())
                self.wfile.write(b'}')
            self.wfile.write(f' {metric["value"]}\n'.encode())

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description = 'Export Borgmatic indicators')
    parser.add_argument('--collector.info-file', dest = 'info_file', action = 'store', required = True,
                                                 help = 'Path to info file in JSON format')
    parser.add_argument('--collector.list-file', dest = 'list_file', action = 'store', required = True,
                                                 help = 'Path to list file export in JSON format')
    parser.add_argument('--web.listen-address', dest = 'bind_addr', action = 'store', default = ':9559',
                                                help = 'Address on which to expose metrics and web interface')
    parser.add_argument('--web.telemetry-path', dest = 'metrics_path', action = 'store', default = '/metrics',
                                                help = 'Path under which to expose metrics')
    config = parser.parse_args()

    if not re.match('^[^:]*:[0-9]+$', config.bind_addr):
        raise ValueError('Malformed listen address')
    if not config.metrics_path.startswith('/'):
        raise ValueError('Malformed telemetry path')

    addr, port = tuple(config.bind_addr.split(':'))
    port = int(port)

    with HTTPServer((addr, port), ExporterHandler) as httpd:
        print('Serving at', config.bind_addr)
        httpd.serve_forever()
